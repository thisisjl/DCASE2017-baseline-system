{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About RawAudioBatcher\n",
    "\n",
    "This Jupyter notebook explains the class RawAudioBatcher, which is used to create batches from audio data.\n",
    "It contains a python generator method that can be used as input to the method `fit_generator` of a Keras neural network model with audio waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.split(os.path.dirname(os.path.realpath('__file__')))[0])\n",
    "from dcase_framework.raw_audio_utils import RawAudioBatcher\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the files\n",
    "For this demo, the five wav files in the `data` folder will be used. Its class labels are defined in the annotations dict. In reality, these labels are read from a text file with the rest of the files in the database.\n",
    "\n",
    "In the same way, the list `class_labels` contains all the possible labels in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_files = os.listdir('data')\n",
    "training_files = [os.path.join('data',tf) for tf in training_files]\n",
    "\n",
    "annotations = \\\n",
    "{'data/a001_140_150.wav': {'file':'data/a001_140_150.wav', 'identifier': 'a001', 'scene_label': 'residential_area'},\n",
    " 'data/a001_160_170.wav': {'file':'data/a001_160_170.wav', 'identifier': 'a001', 'scene_label': 'residential_area'},\n",
    " 'data/a005_110_120.wav': {'file':'data/a005_110_120.wav', 'identifier': 'a005', 'scene_label': 'city_center'},\n",
    " 'data/a006_30_40.wav': {'file':'data/a006_30_40.wav', 'identifier': 'a006', 'scene_label': 'beach'},\n",
    " 'data/a006_50_60.wav': {'file':'data/a006_50_60.wav', 'identifier': 'a006', 'scene_label': 'beach'}}\n",
    "\n",
    "class_labels = ['beach', 'bus', 'cafe/restaurant', 'car', 'city_center', 'forest_path', 'grocery_store',\n",
    " 'home', 'library', 'metro_station', 'office', 'park', 'residential_area', 'train', 'tram']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RawAudioBatcher\n",
    "### Parameters\n",
    "The parameters for RawAudioBatcher are:\n",
    "- **split_files** : list\n",
    "    \n",
    "    Full list of audio files to load\n",
    "\n",
    "\n",
    "- **_annotations** : dict\n",
    "    \n",
    "    Dictionary containing a nested dictionary for each audio file in split_files.\n",
    "    The nested dictionary must contain the keys 'file', 'identifier' and'scene_label'. Example:\n",
    "    {'a001_140_150.wav': {'file':'a001_140_150.wav', 'identifier': 'a001', 'scene_label': 'residential_area'}\n",
    "\n",
    "\n",
    "- **class_labels** : list\n",
    "    \n",
    "    All possible class labels\n",
    "\n",
    "- **batch_size** : int\n",
    "    \n",
    "    Number of audio files to load and output\n",
    "\n",
    "\n",
    "- **mono** : bool\n",
    "    \n",
    "    If True the audio file will be mixed down to a mono file\n",
    "\n",
    "\n",
    "- **desired_fs** : int\n",
    "\n",
    "    Sampling frequency of the output data\n",
    "\n",
    "\n",
    "- **segment** : bool\n",
    "    \n",
    "    Separate the audio file into segments. Its duration defined by frame_size_sec0.\n",
    "\n",
    "\n",
    "- **frame_size_sec0** : float\n",
    "    \n",
    "    number of seconds of each segment if segment is True\n",
    "\n",
    "\n",
    "- **normalize** : bool\n",
    "    \n",
    "    Normalize output values between 0 and 1. If mono is False, channels are normalized with the same value.\n",
    "    \n",
    "\n",
    "### Usage\n",
    "#### Instantiation\n",
    "RawAudioBatcher needs to be instantiated before getting outputs from it. The following cell does that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "mono = True\n",
    "desired_fs = 16000\n",
    "segment = True\n",
    "frame_size_sec0 = 5.0\n",
    "normalize = True\n",
    "\n",
    "train_batcher = RawAudioBatcher(\n",
    "    training_files, annotations, class_labels, batch_size, mono,desired_fs, segment, frame_size_sec0, normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting ouput from instance\n",
    "At the moment only the generator method can be used to get samples from it. The generators need to be called with the python method `next`, see next cell. It will return two items: the audio data and its labels. The labels are one hot encoded.\n",
    "\n",
    "The shape of the audio data is `(batch_size * number of segments, duration, channels)`\n",
    "\n",
    "The shape of the labels matrix is `(batch_size * number of segments, number of classes)`\n",
    "\n",
    "Note that, if `segment` is False, the number of segments is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 80000, 1)\n",
      "(8, 15)\n"
     ]
    }
   ],
   "source": [
    "audio_data, labels = next(train_batcher.generator())\n",
    "\n",
    "print(np.shape(audio_data))\n",
    "print(np.shape(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do soon\n",
    "\n",
    "- apply transformations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcase-ve",
   "language": "python",
   "name": "dcase-ve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
